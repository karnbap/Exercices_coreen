// netlify/functions/analyze-pronunciation.js
// ìš”ì²­: { referenceText:string, audio:{ base64:string, mimeType:string, filename?:string, duration?:number } }
// ì‘ë‹µ: { accuracy:number(0..1), transcript:string, confusionTags:string[] }

const fetch = global.fetch || require('node-fetch');
const FormData = require('form-data');               // â† ê·¸ëŒ€ë¡œ ì‚¬ìš©
const OPENAI_API_KEY = process.env.OPENAI_API_KEY || '';

exports.handler = async (event) => {
  if (event.httpMethod === 'OPTIONS') return { statusCode:204, headers:hdr(), body:'' };
  if (event.httpMethod !== 'POST')    return j(405,{ message:'Method Not Allowed' });

  try {
    const body = JSON.parse(event.body || '{}');
    const ref = String(body.referenceText || '');
    const audio = body.audio || {};
    const b64 = String(audio.base64 || '');
    const mime = String(audio.mimeType || 'audio/webm');
    const duration = Number(audio.duration || 0);
    if (!b64) return j(400, { message:'audio base64 required' });
    if (duration && duration < 0.6) {
      return j(200, { accuracy:0, transcript:'', confusionTags:['trop-court'] });
    }

    // Whisper STT (ko)
    const buf = Buffer.from(b64, 'base64');
    const fd = new FormData();
    fd.append('file', buf, { filename: audio.filename || 'rec.webm', contentType: mime });
    fd.append('model', 'whisper-1');
    fd.append('language', 'ko');
    // ðŸš‘ ì¤‘ìš”: ë©€í‹°íŒŒíŠ¸ í—¤ë”(boundary) í¬í•¨
    const headers = { Authorization:`Bearer ${OPENAI_API_KEY}`, ...fd.getHeaders() };

    const r = await fetch('https://api.openai.com/v1/audio/transcriptions', {
      method:'POST',
      headers,
      body: fd
    });

    if (!r.ok) {
      const t = await r.text().catch(()=> '');
      return j(200, { accuracy:0, transcript:'', confusionTags:[`stt-fail:${r.status}`] });
    }
    const tj = await r.json();
    const hyp = String(tj.text || '').trim();

    const norm = s => String(s||'').replace(/\s+/g,'').replace(/[.,!?;:()"'â€™â€œâ€\-â€“â€”]/g,'');
    const R = norm(ref), H = norm(hyp);

    // ë ˆë²¤ìŠˆíƒ€ì¸ ìœ ì‚¬ë„
    const sim = (a,b) => {
      const n=a.length, m=b.length; if(!n&&!m) return 1; if(!n||!m) return 0;
      const dp=Array.from({length:n+1},()=>Array(m+1).fill(0));
      for(let i=0;i<=n;i++) dp[i][0]=i; for(let j=0;j<=m;j++) dp[0][j]=j;
      for(let i=1;i<=n;i++){ for(let j=1;j<=m;j++){
        const cost=a[i-1]===b[j-1]?0:1;
        dp[i][j]=Math.min(dp[i-1][j]+1, dp[i][j-1]+1, dp[i-1][j-1]+cost);
      }}
      const d=dp[n][m]; return Math.max(0, 1 - d/Math.max(n,1));
    };

    let acc = sim(R,H);

    const tags = [];
    if (/ìš”/.test(ref) && /ìœ /.test(hyp)) tags.push('ìš”â†’ìœ ');
    if (/ìœ¼/.test(ref) && /ìš°/.test(hyp)) tags.push('ìœ¼â†’ìš°');
    if (/ì—/.test(ref) && /ì• /.test(hyp)) tags.push('ì—â†”ì• ');
    if (/ã……/.test(ref) && /ã…†/.test(hyp)) tags.push('ã……â†”ã…†');

    return j(200, { accuracy: Number(acc.toFixed(3)), transcript: hyp, confusionTags: tags });

  } catch (err) {
    console.error(err);
    return j(500, { message:'analyze-pronunciation failed', error:String(err) });
  }
};

function hdr(){ return {
  'Access-Control-Allow-Origin':'*',
  'Access-Control-Allow-Methods':'POST,OPTIONS',
  'Access-Control-Allow-Headers':'Content-Type,Authorization,Accept',
  'Content-Type':'application/json',
  'Cache-Control':'no-store'
};}
function j(statusCode,obj){ return { statusCode, headers:hdr(), body:JSON.stringify(obj) }; }
